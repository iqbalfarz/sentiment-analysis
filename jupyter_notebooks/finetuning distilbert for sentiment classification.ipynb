{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Fine-tuning BERT for Twitter Sentiment Analysis\n\n### There are 4 Steps to fine-tune the model\n#### 1. Tokenizing Text\n#### 2. Defining a Model Architecture\n#### 3. Training Classification Layer Weights\n#### 4. Fine-tuning DistilBERT and Training All Weights","metadata":{}},{"cell_type":"markdown","source":"### Installing transformers","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:10.226646Z","iopub.execute_input":"2022-11-19T13:05:10.227044Z","iopub.status.idle":"2022-11-19T13:05:21.468740Z","shell.execute_reply.started":"2022-11-19T13:05:10.227000Z","shell.execute_reply":"2022-11-19T13:05:21.467413Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading dataset","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:21.472025Z","iopub.execute_input":"2022-11-19T13:05:21.472415Z","iopub.status.idle":"2022-11-19T13:05:21.480018Z","shell.execute_reply.started":"2022-11-19T13:05:21.472383Z","shell.execute_reply":"2022-11-19T13:05:21.479022Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset_dir = Path(\"/kaggle/input/tweeter-clean\")\ntrain = pd.read_csv(dataset_dir/\"train_new.csv\")\ntest = pd.read_csv(dataset_dir/\"test_new.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:21.481805Z","iopub.execute_input":"2022-11-19T13:05:21.482200Z","iopub.status.idle":"2022-11-19T13:05:24.350945Z","shell.execute_reply.started":"2022-11-19T13:05:21.482158Z","shell.execute_reply":"2022-11-19T13:05:24.349955Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:24.353661Z","iopub.execute_input":"2022-11-19T13:05:24.354057Z","iopub.status.idle":"2022-11-19T13:05:24.372980Z","shell.execute_reply.started":"2022-11-19T13:05:24.354020Z","shell.execute_reply":"2022-11-19T13:05:24.371972Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   sentiment_score                                              tweet\n0                0  that is a bummer You should a got David Carr o...\n1                0  is upset that he can not update his Facebook b...\n2                0  I dived many times for the ball Managed to sav...\n3                0     my whole body feels itchy and like its on fire\n4                0  no it is not behaving at i am mad why am i her...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment_score</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>that is a bummer You should a got David Carr o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can not update his Facebook b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>I dived many times for the ball Managed to sav...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>no it is not behaving at i am mad why am i her...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### splitting the dataset into TRAIN, VAL, and TEST","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom time import time\nt0 = time()\nX_train, X_val, y_train, y_val = train_test_split(train.tweet, train.sentiment_score,train_size=0.6, test_size=0.02, random_state=43, stratify=train.sentiment_score)\nX_test, y_test = test.tweet, test.sentiment_score\nprint(f\"time taken to split into TRAIN and VAL: {time()-t0} s\")\nX_train.shape, X_val.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:24.374735Z","iopub.execute_input":"2022-11-19T13:05:24.375107Z","iopub.status.idle":"2022-11-19T13:05:24.825506Z","shell.execute_reply.started":"2022-11-19T13:05:24.375072Z","shell.execute_reply":"2022-11-19T13:05:24.824470Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"time taken to split into TRAIN and VAL: 0.441051721572876 s\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"((957445,), (31915,), (359,))"},"metadata":{}}]},{"cell_type":"code","source":"y_train.value_counts(), y_val.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:24.826905Z","iopub.execute_input":"2022-11-19T13:05:24.827583Z","iopub.status.idle":"2022-11-19T13:05:24.846199Z","shell.execute_reply.started":"2022-11-19T13:05:24.827543Z","shell.execute_reply":"2022-11-19T13:05:24.845246Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(0    478851\n 1    478594\n Name: sentiment_score, dtype: int64,\n 0    15962\n 1    15953\n Name: sentiment_score, dtype: int64)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### 1. Tokenizing Text\nTokenization is a process to make sentence in the form which is expected by the Model (DistilBERT).\nWe can do this using Huggingface APIs.\n\n<img src=\"http://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\">\n\nDifferent pre-trained models utilize different methods to to tokenizer textual inputs (as you can see in the above picture how DistilBERT's includes special tokens such as \\[CLS\\] and \\[SEP\\] in its tokenization scheme).\n\nSo, it is necessary to instantiate a tokenizer object that is specific to our chosen model.\n\nTo get the tokenizer used by `distilbert-base-uncased`, we pass the model's name to the `.from_pretrained()` method of the `DistilBertTokenizerFast` class.","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast\n\ncheckpoint = \"distilbert-base-uncased\"\n# Instantiate DistilBert tokenizer. We use the faster version to optimizer runtime\ntokenizer = DistilBertTokenizerFast.from_pretrained(checkpoint)\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:24.847953Z","iopub.execute_input":"2022-11-19T13:05:24.848358Z","iopub.status.idle":"2022-11-19T13:05:29.171976Z","shell.execute_reply.started":"2022-11-19T13:05:24.848324Z","shell.execute_reply":"2022-11-19T13:05:29.170892Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84637c2bb67e4773a0c8299c11db2d90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec5211c6ed64814a62ebeb676b247c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c527f42c4a747b3972a81a9dca16bb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb942bd910cd40be830b92317831351f"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"},"metadata":{}}]},{"cell_type":"markdown","source":"__Let's tokenize `TRAIN`, `VAL`, and `TEST` split in batches using the tokenizer's `.batch_encode_plus()` method.__\n\nA few arguments to understand in tokenization:\n- `max_length` --> Controls the maximum number of words to tokenize in a give text.\n- `padding` --> If set to `longest`, then pads to the longest sequence in the batch.\n- `truncation` --> If `True`, then truncates text according to the value set by `max_length`\n- `return_attention_mask` --> If `True`, then returns the `attention_mask`. This is optional, but attention masks tell your model that what tokens to pay attention to and which to ignore (in case of padding we pad with fixed token, and we are not suppose to consider that). including the attention mask may improve the model performance.\n\n- `return_token_type_ids` --> If `True`, then returns the `token type IDs`. This is required for some tasks that require multiple sequences as input.\n\nThis is required in Question Answering System where we inform the model that where first sequence ends and seconds sequence starts.\n\nBut, for here we are just passing one sequence. So, this is mandatory here.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n# Define the maximum number of words to tokenizer (DistilBERT can tokenizer upto 512)\n# because maximum tweet length can be of 280 words only.\nMAX_LENGTH = 60 # because of memory issue, we are using this. \n# and the maxlen in the dataset is 52 (after preprocessing)\n\n# Define function to encode text data in batches\ndef batch_encode(tokenizer, texts, batch_size=128, max_length=MAX_LENGTH):\n    \"\"\"\n    A function to encode batch of text and returns the texts'corresponding encodings\n    and attention masks that are ready to be fed into a pre-trained transformer model.\n    \n    Parameters\n    ----------\n        tokenizer: ``PreTrainedTokenizer``\n            Tokenizer object from the PreTrainedTokenizer class\n        texts: ``List[str]``\n            List of strings where each string represents a text\n        batch_size: ``int``\n            size of each batch\n        max_length: ``int``\n            maximum length of the sentence.\n        \n    Returns\n    -------\n        input_ids: ``tf.Tensor``\n            sequence of texts encoded as `tf.Tensor` object\n        attention_mask:\n            the texts' attention mask encoded as a `tf.Tensor` object.\n    \"\"\"\n    input_ids = []\n    attention_mask = []\n    \n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n        inputs = tokenizer.batch_encode_plus(\n            batch_text_or_text_pairs=batch,\n            max_length = max_length,\n            padding='max_length',\n            # truncate to a maximum length specified with \n            # the argument max_length or to the maximum acceptable\n            #input length for thee model if that argument is not provided.\n            truncation='only_first', \n            return_attention_mask=True,\n            return_token_type_ids=False,\n        )\n        input_ids.extend(inputs['input_ids'])\n        attention_mask.extend(inputs['attention_mask'])\n        \n    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_mask)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:29.173654Z","iopub.execute_input":"2022-11-19T13:05:29.174046Z","iopub.status.idle":"2022-11-19T13:05:29.182709Z","shell.execute_reply.started":"2022-11-19T13:05:29.174009Z","shell.execute_reply":"2022-11-19T13:05:29.181454Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"t0 = time()\n# Encode X_train\nX_train_ids, X_train_attention = batch_encode(tokenizer, X_train.tolist())\n\n# Encode X_val\nX_val_ids, X_val_attention = batch_encode(tokenizer, X_val.tolist())\n\n# Encode X_test\nX_test_ids, X_test_attention = batch_encode(tokenizer, X_test.tolist())\nprint(f\"time taken to get inputs ids and attention masks for TRAIN, VAL, and TEST: {time()-t0} s\")","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:05:29.184302Z","iopub.execute_input":"2022-11-19T13:05:29.184643Z","iopub.status.idle":"2022-11-19T13:07:01.715348Z","shell.execute_reply.started":"2022-11-19T13:05:29.184609Z","shell.execute_reply":"2022-11-19T13:07:01.713431Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"time taken to get inputs ids and attention masks for TRAIN, VAL, and TEST: 92.51472520828247 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"__Now we are having the dataset in the form to be passed to the model.__","metadata":{}},{"cell_type":"markdown","source":"#### 2. Defining a Model Architecture\n\nWe have encoded our training, validation, and test splits.\n\nNow, It is time to define our Model architecture. Since, we are using `DistilBERT` as our base model, we begin by importing `distilbert-base-uncased`","metadata":{}},{"cell_type":"code","source":"from transformers import TFDistilBertModel, DistilBertConfig\n\nDISTILBERT_DROPOUT = 0.2 # default is 0.1\nDISTILBERT_ATT_DROPOUT = 0.2 # default is 0.1\n\n# Configure DistilBERT's initialization\nconfig = DistilBertConfig(\n    dropout = DISTILBERT_DROPOUT,\n    attention_dropout = DISTILBERT_ATT_DROPOUT,\n    output_hidden_states=True,\n)\n\n# pre-trained DistilBERT transformer model will output raw hidden-states\n# and without any specific head on top. So, we are suppose to use this for our downstream task.\n# DistilBERT model will be initialized by our custom config (configuration)\ndistilBERT = TFDistilBertModel.from_pretrained(checkpoint, config=config)\n\n# freeze the DistilBERT layers (means untrainable)\n# we can later unfreeze when model performance converges.\nfor layer in distilBERT.layers:\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:07:01.719145Z","iopub.execute_input":"2022-11-19T13:07:01.719435Z","iopub.status.idle":"2022-11-19T13:07:24.025713Z","shell.execute_reply.started":"2022-11-19T13:07:01.719407Z","shell.execute_reply":"2022-11-19T13:07:24.024792Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f580ae4ac1274c61b4d491cf867be80f"}},"metadata":{}},{"name":"stderr","text":"2022-11-19 13:07:19.236212: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\nSome layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"for the detailed parameters for configuration please go to [this](https://huggingface.co/transformers/v3.0.2/model_doc/distilbert.html#distilbertconfig) link.","metadata":{}},{"cell_type":"markdown","source":"<b>Now, we will add our own head on top of the model we get.","metadata":{}},{"cell_type":"markdown","source":"#### Add a Classification Head","metadata":{}},{"cell_type":"code","source":"# Path to save the distilbert model\nmodel_dir = Path(\"./models\")\ncheckpoint_path_distilbert = model_dir/\"best_distil_model.tf\"\n\nif not model_dir.exists():\n    model_dir.mkdir()\n    \n# Callbacks to save model \nsave_distilbert_model = tf.keras.callbacks.ModelCheckpoint(\n    filepath = checkpoint_path_distilbert,\n    monitor=\"val_accuracy\",\n    save_best_only=True,\n    verbose=1,\n    mode=\"max\", # save model when get max validation accuracy\n)\n\n# Early stop\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=3,\n    mode=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:07:24.027576Z","iopub.execute_input":"2022-11-19T13:07:24.027932Z","iopub.status.idle":"2022-11-19T13:07:24.034731Z","shell.execute_reply.started":"2022-11-19T13:07:24.027896Z","shell.execute_reply":"2022-11-19T13:07:24.033568Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"LAYER_DROPOUT = 0.2\nLEARNING_RATE = 5e-5 # recommended by BERT author's\nRANDOM_STATE = 42\n\ndef build_model(transformer, max_length=MAX_LENGTH):\n    \"\"\"\n    Template for building a model on top of BERT or DistilBERT architecture\n    for a binary classification task.\n    \n    Parameters\n    ----------\n        transformer:\n            A base Huggingface transformer model object (BERT or DistilBERT)\n            with no added classification head on top of it.\n        max_length: int\n            maximum number of encoded tokens in a given sequence.\n            \n    Returns\n    -------\n        model:\n            A compiled `tf.keras.Model` with added classification layers\n            on top of the base pre-trained model architecture.\n    \"\"\"\n    \n    # define weight initializer with a random sed to ensure reproducibility\n    weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE)\n    \n    # define input layers\n    input_ids_layer = tf.keras.layers.Input(shape=(max_length,),\n                                            name='input_ids',\n                                            dtype='int32',\n                                           )\n    input_attention_layer = tf.keras.layers.Input(shape=(max_length,),\n                                                  name=\"input_attention\",\n                                                  dtype='int16'\n                                                 )\n    \n    # DistilBERT outputs a tuple where the first element at index 0\n    # represents the hidden-state at the output of the model's last layer.\n    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n    \n    # We only care about DistilBERT's output for the [CLS] token, \n    # which is located at index 0 of every encoded sequence.  \n    # Slicing out the [CLS] tokens gives us 2D data.\n    # [CLS] stands for Classification\n    cls_token = last_hidden_state[:, 0, :]\n    \n    #                                                 ##\n    # Define additional dropout and dense layers here ##\n    #                                                 ##\n    \n    # Define a single node that makes up the output layer (for binary classification)\n    dense1 = tf.keras.layers.Dense(200,\n                                   activation='relu',\n                                   kernel_initializer='he_normal',\n                                  )(cls_token)\n    dense2 = tf.keras.layers.Dense(\n        100,\n        activation='relu',\n        kernel_initializer='he_normal',\n    )(dense1)\n    output = tf.keras.layers.Dense(1, \n                                   activation='sigmoid',\n                                   kernel_initializer=weight_initializer,  \n                                   kernel_constraint=None,\n                                   bias_initializer='zeros'\n                                   )(dense2)\n    \n    # Define the model\n    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n    \n    # Compile the model\n    model.compile(tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), \n                  loss='binary_crossentropy',\n                  metrics=['accuracy'],)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:07:24.036219Z","iopub.execute_input":"2022-11-19T13:07:24.036822Z","iopub.status.idle":"2022-11-19T13:07:24.049316Z","shell.execute_reply.started":"2022-11-19T13:07:24.036785Z","shell.execute_reply":"2022-11-19T13:07:24.048261Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Create model","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\ndistilbert_model = build_model(distilBERT,)\ndistilbert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:07:24.050840Z","iopub.execute_input":"2022-11-19T13:07:24.051198Z","iopub.status.idle":"2022-11-19T13:07:27.533555Z","shell.execute_reply.started":"2022-11-19T13:07:24.051164Z","shell.execute_reply":"2022-11-19T13:07:27.532545Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 60)]         0                                            \n__________________________________________________________________________________________________\ninput_attention (InputLayer)    [(None, 60)]         0                                            \n__________________________________________________________________________________________________\ntf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n                                                                 input_attention[0][0]            \n__________________________________________________________________________________________________\ntf.__operators__.getitem (Slici (None, 768)          0           tf_distil_bert_model[0][7]       \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 200)          153800      tf.__operators__.getitem[0][0]   \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 100)          20100       dense[0][0]                      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n==================================================================================================\nTotal params: 66,536,881\nTrainable params: 174,001\nNon-trainable params: 66,362,880\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 3. Traninig Classification Layer Weights\n","metadata":{}},{"cell_type":"code","source":"X_val_ids.shape, X_val_attention.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:07:27.534802Z","iopub.execute_input":"2022-11-19T13:07:27.535760Z","iopub.status.idle":"2022-11-19T13:07:27.543422Z","shell.execute_reply.started":"2022-11-19T13:07:27.535719Z","shell.execute_reply":"2022-11-19T13:07:27.542367Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(TensorShape([31915, 60]), TensorShape([31915, 60]))"},"metadata":{}}]},{"cell_type":"code","source":"EPOCHS = 20\nBATCH_SIZE = 128 # memory constraints\nNUM_STEPS = len(X_train.index) // BATCH_SIZE\nTOTAL = 20000\n\ntrain = False\nif train is True:\n    # Train the model\n    distilbert_model_history = distilbert_model.fit(\n        x = [X_train_ids, X_train_attention],\n        y = y_train.to_numpy(),\n        epochs = EPOCHS,\n        batch_size = BATCH_SIZE,\n        steps_per_epoch = NUM_STEPS,\n        validation_data = ([X_val_ids, X_val_attention], y_val.to_numpy()),\n        verbose=1,\n        callbacks = [save_distilbert_model, early_stop]\n    )\nelse:\n    print(\"Please make train as True to train the model\")","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:07:27.544877Z","iopub.execute_input":"2022-11-19T13:07:27.547087Z","iopub.status.idle":"2022-11-19T13:07:27.555586Z","shell.execute_reply.started":"2022-11-19T13:07:27.547049Z","shell.execute_reply":"2022-11-19T13:07:27.554646Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Please make train as True to train the model\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### See the Classification report on TEST dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\ndef classification_report_dl(model, test_data, test_label, model_name=\"DistilBERT Model\"):\n    \"\"\"This function shows the classification report of given model on the given dataset.\"\"\"\n    \n    ################ TRAIN ERROR and ACCURACY ###################\n    # prediction of test dataset using best given Model\n    test_predicted = pd.Series((model.predict(test_data)).flatten()).apply(lambda x: 1 if x>0.5 else 0)\n    \n    test_accuracy = accuracy_score(test_label, test_predicted)\n\n    test_f1_score = f1_score(test_label, test_predicted)\n\n    print(\"TEST Accuracy : \",test_accuracy)\n    print(\"=\"*50)\n    print(\"TEST f1-score : \",test_f1_score)\n    ###########################################################################\n\n    ############### CLASSIFICATIO RESULT of both Train, and Test dataset ######\n    test_cf_report = classification_report(test_label, test_predicted)\n\n    print(\"-------------------------\")\n    print(\"| Classification Report |\")\n    print(\"-------------------------\")\n    print(\"TEST : \")\n    print(test_cf_report)\n    print(\"-------------------------\")\n    \n    #############################################################################################\n\n    ################### ROC-AUC Score ###########################################################\n    # getting train_score, and test_score\n    test_prob = model.predict(test_data)\n\n    # area under the curve\n    test_auc = roc_auc_score(test_label, test_prob)\n\n    ns_probs_test = [0 for _ in range(len(test_label))] # no skill probability for test dataset\n\n    ##########  TRAIN AUC  ###########\n    fpr_test, tpr_test, _ = roc_curve(test_label, test_prob)\n\n    ns_fpr, ns_tpr, _ = roc_curve(test_label, ns_probs_test) # this is for no-skill\n\n    plt.plot(fpr_test,tpr_test,label='TEST AUC Score={}'.format(test_auc))\n    plt.plot(ns_fpr, ns_tpr, label='No skill')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(\"TEST AUC Score of best {}\".format(model_name))\n    plt.legend() # to show the label on plot\n    plt.savefig(\"./results/distil.png\")\n    plt.show() # force to show the plot\n","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:48:46.996123Z","iopub.execute_input":"2022-11-19T13:48:46.996514Z","iopub.status.idle":"2022-11-19T13:48:47.008557Z","shell.execute_reply.started":"2022-11-19T13:48:46.996481Z","shell.execute_reply":"2022-11-19T13:48:47.007409Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"X_test_ids.shape, X_test_attention.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:48:48.417642Z","iopub.execute_input":"2022-11-19T13:48:48.418033Z","iopub.status.idle":"2022-11-19T13:48:48.425792Z","shell.execute_reply.started":"2022-11-19T13:48:48.417977Z","shell.execute_reply":"2022-11-19T13:48:48.424565Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"(TensorShape([359, 60]), TensorShape([359, 60]))"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir results/","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:48:48.538749Z","iopub.execute_input":"2022-11-19T13:48:48.539112Z","iopub.status.idle":"2022-11-19T13:48:49.654429Z","shell.execute_reply.started":"2022-11-19T13:48:48.539080Z","shell.execute_reply":"2022-11-19T13:48:49.653170Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nmkdir: cannot create directory ‘results/’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"# best_distil_model = tf.keras.models.load_model(\"./models/best_distil_model.tf\",\n#                                                custom_objects={\"TFDistilBertModel\":distilBERT})\nbest_distil_model = tf.keras.models.load_model(\"./models/best_distil_model.tf\")\nbest_distil_model","metadata":{"execution":{"iopub.status.busy":"2022-11-19T14:03:42.615931Z","iopub.execute_input":"2022-11-19T14:03:42.616960Z","iopub.status.idle":"2022-11-19T14:03:49.979868Z","shell.execute_reply.started":"2022-11-19T14:03:42.616921Z","shell.execute_reply":"2022-11-19T14:03:49.978733Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"<keras.engine.functional.Functional at 0x7fbd3e2a02d0>"},"metadata":{}}]},{"cell_type":"code","source":"classification_report_dl(\n    model = best_distil_model,\n    test_data = [X_test_ids, X_test_attention],\n    test_label = y_test.to_numpy(),\n    model_name=\"DistilBERT model\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:48:52.392351Z","iopub.execute_input":"2022-11-19T13:48:52.392749Z","iopub.status.idle":"2022-11-19T13:48:53.728888Z","shell.execute_reply.started":"2022-11-19T13:48:52.392714Z","shell.execute_reply":"2022-11-19T13:48:53.727945Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"TEST Accuracy :  0.8161559888579387\n==================================================\nTEST f1-score :  0.8176795580110496\n-------------------------\n| Classification Report |\n-------------------------\nTEST : \n              precision    recall  f1-score   support\n\n           0       0.81      0.82      0.81       177\n           1       0.82      0.81      0.82       182\n\n    accuracy                           0.82       359\n   macro avg       0.82      0.82      0.82       359\nweighted avg       0.82      0.82      0.82       359\n\n-------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}